{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAN-Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMv0VbN5GhX31yGtOLjDIFd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meabhl85/Canvas-System/blob/main/CAN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7k6lFXEepEC"
      },
      "source": [
        "#### Imports and Google Drive Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFZafEk_YxSj",
        "outputId": "91bbbc13-3a99-40a1-90e5-8cedcad20e17"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense \n",
        "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.constraints import Constraint\n",
        "from tensorflow.keras import backend\n",
        "import numpy as np\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from numpy import ones\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os \n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "#Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "  h = int(sec_elapsed / (60 * 60))\n",
        "  m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "  s = sec_elapsed % 60\n",
        "  return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TntaaV_HeuQX"
      },
      "source": [
        "#### Model Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kknpzagDYznZ"
      },
      "source": [
        "#Image Sizes\n",
        "GENERATE_RES = 5 # Generation resolution factor \n",
        "GENERATE_SQUARE = 32 * GENERATE_RES # rows/cols (should be square)\n",
        "IMAGE_CHANNELS = 3\n",
        "\n",
        "#Input and Output PathsA\n",
        "NPY_FILES_PATH = '/content/drive/MyDrive/Colab Notebooks/honours_project/Npy_Files/'\n",
        "OUTPUT_IMAGE_PATH = '/content/drive/MyDrive/Colab Notebooks/honours_project/GAN_Images/'\n",
        "\n",
        "# Preview image \n",
        "PREVIEW_ROWS = 2\n",
        "PREVIEW_COLS = 3\n",
        "PREVIEW_MARGIN = 16\n",
        "\n",
        "# Size vector to generate images from\n",
        "SEED_SIZE = 800\n",
        "EPOCHS = 1000\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 60000"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlIJPkFIe5lD"
      },
      "source": [
        "#### Model Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2TBkgaYY1-F"
      },
      "source": [
        "class CAN:\n",
        "  def __init__(self):\n",
        "    self.class_count = 0\n",
        "    class_names = []\n",
        "    init = True\n",
        "    self.image_shape = (GENERATE_SQUARE, GENERATE_SQUARE, IMAGE_CHANNELS)\n",
        "    #Define cross_entropy function\n",
        "    self.cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "    for filename in tqdm(os.listdir(NPY_FILES_PATH)):\n",
        "      npy_file = os.path.join(NPY_FILES_PATH, filename)\n",
        "      class_names.append(filename)\n",
        "      AC_training_data = np.load(npy_file)\n",
        "      AC_labels = [self.class_count] * len(AC_training_data)\n",
        "      AC_labels = np.array(AC_labels)\n",
        "\n",
        "      if init == True:\n",
        "        self.training_data = AC_training_data\n",
        "        self.training_labels = AC_labels\n",
        "        init == False\n",
        "      else:  \n",
        "        #Combine files\n",
        "        self.training_data = np.concatenate([self.training_data, AC_training_data])\n",
        "        self.training_labels = np.concatenate([self.training_labels, AC_labels])\n",
        "    self.training_dataset = tf.data.Dataset.from_tensor_slices(self.training_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)  \n",
        "    self.training_labels = tf.data.Dataset.from_tensor_slices(self.training_labels).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "    self.class_count += 1\n",
        "\n",
        "\n",
        "  def build_generator(self):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(4*4*256, activation = \"relu\", input_dim = SEED_SIZE))\n",
        "    model.add(Reshape((4, 4, 256)))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(256, kernel_size = 3, padding = \"same\"))\n",
        "    model.add(BatchNormalization(momentum = 0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(256, kernel_size = 3, padding = \"same\"))\n",
        "    model.add(BatchNormalization(momentum = 0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "   \n",
        "    # Output resolution, additional upsampling\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, kernel_size = 3, padding = \"same\"))\n",
        "    model.add(BatchNormalization(momentum = 0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    if GENERATE_RES > 1:\n",
        "      model.add(UpSampling2D(size = (GENERATE_RES, GENERATE_RES)))\n",
        "      model.add(Conv2D(128,kernel_size=3, padding=\"same\"))\n",
        "      model.add(BatchNormalization(momentum = 0.8))\n",
        "      model.add(Activation(\"relu\"))\n",
        "\n",
        "    # Final CNN layer\n",
        "    model.add(Conv2D(IMAGE_CHANNELS, kernel_size=3, padding=\"same\"))\n",
        "    model.add(Activation(\"tanh\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "  # def build_discriminator(self):\n",
        "    \n",
        "  #   init = RandomNormal(stddev=0.02)\n",
        "  #   inputs = tf.keras.Input(shape=self.image_shape)\n",
        "\n",
        "  #   x = tf.random.normal(self.image_shape)\n",
        "\n",
        "  #   #Layer 1\n",
        "  #   # layer_1 = tf.keras.layers.Conv2D(32, kernel_size = 3, strides = 2, padding = \"same\", input_shape=image_shape[1:])(x)\n",
        "  #   layer_1 = tf.keras.layers.Conv2D(32, kernel_size = 3, kernel_initializer=init, strides = 2, padding = \"same\")(inputs)\n",
        "  #   relu_1 = tf.keras.layers.LeakyReLU(alpha = 0.2)(layer_1)\n",
        "\n",
        "  #   #Layer 2\n",
        "  #   dropout_1 = tf.keras.layers.Dropout(0.25)(relu_1)\n",
        "  #   layer_2 = tf.keras.layers.Conv2D(64, kernel_size = 3, kernel_initializer=init, strides = 2, padding = \"same\")(dropout_1)\n",
        "  #   zero_padding_1 = tf.keras.layers.ZeroPadding2D(padding = ((0, 1), (0, 1)))(layer_2)\n",
        "  #   batch_norm_1 = tf.keras.layers.BatchNormalization(momentum = 0.8)(zero_padding_1)\n",
        "  #   relu_2 = tf.keras.layers.LeakyReLU(alpha = 0.2)(batch_norm_1)\n",
        "\n",
        "  #   #Layer 3\n",
        "  #   dropout_2 = tf.keras.layers.Dropout(0.25)(relu_2)\n",
        "  #   layer_3 = tf.keras.layers.Conv2D(128, kernel_size = 3, kernel_initializer=init, strides = 2, padding = \"same\")(dropout_2)\n",
        "  #   batch_norm_2 = tf.keras.layers.BatchNormalization(momentum = 0.8)(layer_3)\n",
        "  #   relu_3 = tf.keras.layers.LeakyReLU(alpha = 0.2)(batch_norm_2)\n",
        "\n",
        "  #   #Layer 4 \n",
        "  #   dropout_3 = tf.keras.layers.Dropout(0.25)(relu_3)\n",
        "  #   layer_4 = tf.keras.layers.Conv2D(256, kernel_size = 3, kernel_initializer=init, strides = 1, padding = \"same\")(dropout_3)\n",
        "  #   batch_norm_3 = tf.keras.layers.BatchNormalization(momentum = 0.8)(layer_4)\n",
        "  #   relu_4 = tf.keras.layers.LeakyReLU(alpha = 0.2)(batch_norm_3)\n",
        "\n",
        "  #   #Layer 5\n",
        "  #   dropout_4 = tf.keras.layers.Dropout(0.25)(relu_4)\n",
        "  #   layer_5 = tf.keras.layers.Conv2D(512, kernel_size = 3, kernel_initializer=init, strides = 1, padding = \"same\")(dropout_4)\n",
        "  #   batch_norm_4 = tf.keras.layers.BatchNormalization(momentum = 0.8)(layer_5)\n",
        "  #   relu_5 = tf.keras.layers.LeakyReLU(alpha = 0.2)(batch_norm_4)\n",
        "\n",
        "  #   #Real/Fake Output\n",
        "  #   dropout_5 = tf.keras.layers.Dropout(0.25)(relu_5)\n",
        "  #   flatten_1 = tf.keras.layers.Flatten()(dropout_5)\n",
        "  #   discriminator_output = tf.keras.layers.Dense(1, kernel_initializer=init, name=\"RF_Output\")(flatten_1)\n",
        "\n",
        "  #   #Layer 7\n",
        "  #   layer_7 = tf.keras.layers.Dense(1024, kernel_initializer=init, name = 'd_h8_lin')(relu_5)\n",
        "  #   relu_7 = tf.keras.layers.LeakyReLU(alpha = 0.2)(layer_7)\n",
        "\n",
        "  #   #Layer 8\n",
        "  #   layer_8 = tf.keras.layers.Dense(512, kernel_initializer=init, name = 'd_h9_lin')(relu_7)\n",
        "  #   relu_7 = tf.keras.layers.LeakyReLU(alpha = 0.2)(layer_8)\n",
        "    \n",
        "  #   flatten_2 = tf.keras.layers.Flatten()(relu_7)\n",
        "  #   discriminator_class_output = tf.keras.layers.Dense(self.class_count, kernel_initializer=init, name = 'd_co_lin')(flatten_2)\n",
        "  #   discriminator_class_output_softmax = tf.nn.softmax(discriminator_class_output)   \n",
        "\n",
        "  #   # #Class Output\n",
        "  #   # output_2 = tf.keras.layers.Dense(class_count, activation=tf.nn.softmax, name=\"Class_Output\")(discriminator_class_output)\n",
        "  #   model = tf.keras.Model(inputs = inputs, outputs = [tf.nn.sigmoid(discriminator_output), discriminator_output, discriminator_class_output, discriminator_class_output_softmax])\n",
        "\n",
        "  #   h0 = tf.keras.layers.lrelu(tf.keras.layers.conv2d(inputs, 32, k_h=4, k_w=4, name='d_h0_conv',padding='VALID'))\n",
        "  #   h1 = lrelu(model.d_bn1(conv2d(h0, model.df_dim*2, k_h=4, k_w=4, name='d_h1_conv', padding='VALID')))\n",
        "  #   h2 = lrelu(model.d_bn2(conv2d(h1, model.df_dim*4, k_h=4, k_w=4, name='d_h2_conv', padding='VALID')))\n",
        "  #   h3 = lrelu(model.d_bn3(conv2d(h2, model.df_dim*8, k_h=4, k_w=4, name='d_h3_conv', padding='VALID')))\n",
        "  #   h4 = lrelu(model.d_bn4(conv2d(h3, model.df_dim*16, k_h=4, k_w=4, name='d_h4_conv', padding='VALID')))\n",
        "  #   shape = np.product(h4.get_shape()[1:].as_list())\n",
        "  #   h5 = tf.reshape(h4, [-1, shape])\n",
        "  #   #linear layer to determine if the image is real/fake\n",
        "  #   r_out = linear(h5, 1, 'd_ro_lin')\n",
        "\n",
        "  #   #fully connected layers to classify the image into the different styles.\n",
        "  #   h6 = lrelu(linear(h5, 1024, 'd_h6_lin'))\n",
        "  #   h7 = lrelu(linear(h6, 512, 'd_h7_lin'))\n",
        "  #   c_out = linear(h7, model.y_dim, 'd_co_lin')\n",
        "  #   c_softmax = tf.nn.softmax(c_out)\n",
        "\n",
        "  #   return model\n",
        "\n",
        "  def build_d1(self):\n",
        "    \n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    inputs = tf.keras.Input(shape=self.image_shape)\n",
        "\n",
        "    x = tf.random.normal(self.image_shape)\n",
        "\n",
        "    #Layer 1\n",
        "    # layer_1 = tf.keras.layers.Conv2D(32, kernel_size = 3, strides = 2, padding = \"same\", input_shape=image_shape[1:])(x)\n",
        "    layer_1 = tf.keras.layers.Conv2D(32, kernel_size = 3, kernel_initializer=init, strides = 2, padding = \"same\")(inputs)\n",
        "    relu_1 = tf.keras.layers.LeakyReLU(alpha = 0.2)(layer_1)\n",
        "\n",
        "    #Layer 2\n",
        "    dropout_1 = tf.keras.layers.Dropout(0.25)(relu_1)\n",
        "    layer_2 = tf.keras.layers.Conv2D(64, kernel_size = 3, kernel_initializer=init, strides = 2, padding = \"same\")(dropout_1)\n",
        "    zero_padding_1 = tf.keras.layers.ZeroPadding2D(padding = ((0, 1), (0, 1)))(layer_2)\n",
        "    batch_norm_1 = tf.keras.layers.BatchNormalization(momentum = 0.8)(zero_padding_1)\n",
        "    relu_2 = tf.keras.layers.LeakyReLU(alpha = 0.2)(batch_norm_1)\n",
        "\n",
        "    #Layer 3\n",
        "    dropout_2 = tf.keras.layers.Dropout(0.25)(relu_2)\n",
        "    layer_3 = tf.keras.layers.Conv2D(128, kernel_size = 3, kernel_initializer=init, strides = 2, padding = \"same\")(dropout_2)\n",
        "    batch_norm_2 = tf.keras.layers.BatchNormalization(momentum = 0.8)(layer_3)\n",
        "    relu_3 = tf.keras.layers.LeakyReLU(alpha = 0.2)(batch_norm_2)\n",
        "\n",
        "    #Layer 4 \n",
        "    dropout_3 = tf.keras.layers.Dropout(0.25)(relu_3)\n",
        "    layer_4 = tf.keras.layers.Conv2D(256, kernel_size = 3, kernel_initializer=init, strides = 1, padding = \"same\")(dropout_3)\n",
        "    batch_norm_3 = tf.keras.layers.BatchNormalization(momentum = 0.8)(layer_4)\n",
        "    relu_4 = tf.keras.layers.LeakyReLU(alpha = 0.2)(batch_norm_3)\n",
        "\n",
        "    #Layer 5\n",
        "    dropout_4 = tf.keras.layers.Dropout(0.25)(relu_4)\n",
        "    layer_5 = tf.keras.layers.Conv2D(512, kernel_size = 3, kernel_initializer=init, strides = 1, padding = \"same\")(dropout_4)\n",
        "    batch_norm_4 = tf.keras.layers.BatchNormalization(momentum = 0.8)(layer_5)\n",
        "    relu_5 = tf.keras.layers.LeakyReLU(alpha = 0.2)(batch_norm_4)\n",
        "\n",
        "    #Real/Fake Output\n",
        "    dropout_5 = tf.keras.layers.Dropout(0.25)(relu_5)\n",
        "    flatten_1 = tf.keras.layers.Flatten()(dropout_5)\n",
        "    discriminator_output = tf.keras.layers.Dense(1, kernel_initializer=init, name=\"RF_Output\")(flatten_1)\n",
        "\n",
        "    # #Class Output\n",
        "    # output_2 = tf.keras.layers.Dense(class_count, activation=tf.nn.softmax, name=\"Class_Output\")(discriminator_class_output)\n",
        "    model = tf.keras.Model(inputs = inputs, outputs = [tf.nn.sigmoid(discriminator_output), discriminator_output])\n",
        "\n",
        "    # model.summary()\n",
        "    return model\n",
        "\n",
        "  def build_d2(self):\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    inputs = tf.keras.Input(shape=self.image_shape)\n",
        "\n",
        "    x = tf.random.normal(self.image_shape)\n",
        "\n",
        "    #Layer 1\n",
        "    # layer_1 = tf.keras.layers.Conv2D(32, kernel_size = 3, strides = 2, padding = \"same\", input_shape=image_shape[1:])(x)\n",
        "    layer_1 = tf.keras.layers.Conv2D(32, kernel_size = 3, kernel_initializer=init, strides = 2, padding = \"same\")(inputs)\n",
        "    relu_1 = tf.keras.layers.LeakyReLU(alpha = 0.2)(layer_1)\n",
        "\n",
        "    #Layer 2\n",
        "    dropout_1 = tf.keras.layers.Dropout(0.25)(relu_1)\n",
        "    layer_2 = tf.keras.layers.Conv2D(64, kernel_size = 3, kernel_initializer=init, strides = 2, padding = \"same\")(dropout_1)\n",
        "    zero_padding_1 = tf.keras.layers.ZeroPadding2D(padding = ((0, 1), (0, 1)))(layer_2)\n",
        "    batch_norm_1 = tf.keras.layers.BatchNormalization(momentum = 0.8)(zero_padding_1)\n",
        "    relu_2 = tf.keras.layers.LeakyReLU(alpha = 0.2)(batch_norm_1)\n",
        "\n",
        "    #Layer 3\n",
        "    dropout_2 = tf.keras.layers.Dropout(0.25)(relu_2)\n",
        "    layer_3 = tf.keras.layers.Conv2D(128, kernel_size = 3, kernel_initializer=init, strides = 2, padding = \"same\")(dropout_2)\n",
        "    batch_norm_2 = tf.keras.layers.BatchNormalization(momentum = 0.8)(layer_3)\n",
        "    relu_3 = tf.keras.layers.LeakyReLU(alpha = 0.2)(batch_norm_2)\n",
        "\n",
        "    #Layer 4 \n",
        "    dropout_3 = tf.keras.layers.Dropout(0.25)(relu_3)\n",
        "    layer_4 = tf.keras.layers.Conv2D(256, kernel_size = 3, kernel_initializer=init, strides = 1, padding = \"same\")(dropout_3)\n",
        "    batch_norm_3 = tf.keras.layers.BatchNormalization(momentum = 0.8)(layer_4)\n",
        "    relu_4 = tf.keras.layers.LeakyReLU(alpha = 0.2)(batch_norm_3)\n",
        "\n",
        "    #Layer 5\n",
        "    dropout_4 = tf.keras.layers.Dropout(0.25)(relu_4)\n",
        "    layer_5 = tf.keras.layers.Conv2D(512, kernel_size = 3, kernel_initializer=init, strides = 1, padding = \"same\")(dropout_4)\n",
        "    batch_norm_4 = tf.keras.layers.BatchNormalization(momentum = 0.8)(layer_5)\n",
        "    relu_5 = tf.keras.layers.LeakyReLU(alpha = 0.2)(batch_norm_4)\n",
        "\n",
        "    #Real/Fake Output\n",
        "    dropout_5 = tf.keras.layers.Dropout(0.25)(relu_5)\n",
        "    flatten_1 = tf.keras.layers.Flatten()(dropout_5)\n",
        "    discriminator_output = tf.keras.layers.Dense(self.class_count, kernel_initializer=init, name=\"Class_Output\")(flatten_1)\n",
        "\n",
        "    # #Class Output\n",
        "    output_2 = tf.nn.softmax(discriminator_output)\n",
        "    model = tf.keras.Model(inputs = inputs, outputs = [output_2, discriminator_output])\n",
        "\n",
        "    # model.summary()\n",
        "    return model\n",
        "\n",
        "  def discriminator_rf_loss(self, disc_output_linear, disc_output_sigmoid):\n",
        "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = disc_output_linear, \n",
        "                                                                labels = tf.ones_like(disc_output_sigmoid)))\n",
        "\n",
        "  def discriminator_class_loss(self, disc_class_output, training_class_output):\n",
        "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = disc_class_output, \n",
        "                                                                  labels = training_class_output))\n",
        "\n",
        "  # def generator_class_loss(disc_class_output, disc_class_output_softmax):\n",
        "  #   return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = disc_class_output,\n",
        "                                                                  # labels = (1.0 / 27) * tf.ones_like(disc_class_output_softmax)))\n",
        "\n",
        "  def generator_class_loss(self, disc_class_output, disc_class_output_softmax):\n",
        "    # training_labels = tf.convert_to_tensor(, np.float32)\n",
        "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = disc_class_output,\n",
        "                                                                  labels = (1.0 / self.class_count) * tf.ones_like(disc_class_output_softmax)))\n",
        "\n",
        "  def discriminator_total_loss(self, real_disc_output_linear, real_disc_output_sigmoid, fake_disc_output_linear, fake_disc_output_sigmoid, real_image_labels, real_disc_class_output):\n",
        "      discriminator_real_loss = discriminator_rf_loss(real_disc_output_linear, real_disc_output_sigmoid)\n",
        "      discriminator_fake_loss = discriminator_rf_loss(fake_disc_output_linear, fake_disc_output_sigmoid)\n",
        "\n",
        "      real_image_labels = tf.cast(real_image_labels, tf.float32)\n",
        "      real_disc_class_output = tf.convert_to_tensor(real_disc_class_output, np.float32)\n",
        "\n",
        "      discriminator_loss_class_real = discriminator_class_loss(real_disc_class_output, real_image_labels)\n",
        "\n",
        "      discriminator_l = discriminator_real_loss + discriminator_fake_loss + discriminator_loss_class_real\n",
        "\n",
        "      return discriminator_l\n",
        "\n",
        "  def generator_loss(self, fake_pred):\n",
        "    #As G wants to create real images the loss is cross entropy of 1's and the generated output\n",
        "    return self.cross_entropy(tf.ones_like(fake_pred), fake_pred)\n",
        "\n",
        "  def discriminator_loss(self, real_pred, fake_pred):\n",
        "    #D should compare the real predictions to 1 and fake to 0 (as they are the real values)\n",
        "    real_image_loss = self.cross_entropy(tf.ones_like(real_pred), real_pred)\n",
        "    fake_image_loss = self.cross_entropy(tf.zeros_like(fake_pred), fake_pred)\n",
        "\n",
        "    #Discriminator uses the complete loss\n",
        "    final_loss = real_image_loss + fake_image_loss\n",
        "    return final_loss\n",
        "\n",
        "  def compile_models(self):\n",
        "    self.d1_optimiser = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
        "    self.generator_optimiser = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
        "    self.d2_optimiser = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
        "\n",
        "  # @tf.function\n",
        "  def step(self, real_images, real_image_labels):\n",
        "    seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
        "\n",
        "    #Performs automatic differentiation used for backpropagation \n",
        "    with tf.GradientTape() as g_tape, tf.GradientTape() as d1_tape, tf.GradientTape() as d2_tape:\n",
        "      #Generate images with noise vector\n",
        "      generated_images = self.generator(seed, training = True)\n",
        "\n",
        "      #Put resulting image into the D and return prediction\n",
        "      # real_disc_output_sigmoid, real_disc_output_linear, real_disc_class_output, real_disc_class_output_softmax = self.discriminator(real_images, training = True)\n",
        "      real_disc_output_sigmoid, real_disc_output_linear = self.d1(real_images, training = True)\n",
        "      real_disc_class_output, real_disc_class_output_softmax = self.d2(real_images, training = True)\n",
        "\n",
        "      real_disc_class_output = np.argmax(real_disc_class_output, 1)\n",
        "      real_disc_class_output_softmax = np.argmax(real_disc_class_output_softmax, 1)\n",
        "\n",
        "      fake_disc_output_sigmoid, fake_disc_output_linear = self.d1(generated_images, training = True)\n",
        "      fake_disc_class_output, fake_disc_class_output_softmax = self.d2(generated_images, training = True)\n",
        "      fake_disc_class_output = np.argmax(fake_disc_class_output, 1)\n",
        "      fake_disc_class_output_softmax = np.argmax(fake_disc_class_output_softmax, 1)\n",
        "      \n",
        "      #DISCRIMINATOR LOSS\n",
        "      discriminator_real_loss = self.discriminator_rf_loss(real_disc_output_linear, real_disc_output_sigmoid)\n",
        "      discriminator_fake_loss = self.discriminator_rf_loss(fake_disc_output_linear, fake_disc_output_sigmoid)\n",
        "\n",
        "      real_image_labels = tf.cast(real_image_labels, tf.float32)\n",
        "      real_disc_class_output = tf.convert_to_tensor(real_disc_class_output, np.float32)\n",
        "      discriminator_loss_class_real = self.discriminator_class_loss(real_disc_class_output, real_image_labels)\n",
        "      \n",
        "      # discriminator_loss = discriminator_real_loss + discriminator_fake_loss + discriminator_loss_class_real\n",
        "      discriminator_loss = discriminator_real_loss + discriminator_fake_loss\n",
        "\n",
        "      #GENERATOR LOSS\n",
        "      a = tf.ones_like(fake_disc_class_output_softmax)\n",
        "      fake_disc_class_output_softmax_temp = (1.0 / 27) * a.numpy()\n",
        "      fake_disc_class_output_softmax_temp = tf.convert_to_tensor(fake_disc_class_output_softmax_temp, np.float32)\n",
        "      fake_disc_class_output = tf.convert_to_tensor(fake_disc_class_output, np.float32)\n",
        "\n",
        "      generator_loss_class_fake = self.generator_class_loss(fake_disc_class_output, fake_disc_class_output_softmax_temp)\n",
        "      generator_loss_fake = self.discriminator_rf_loss(fake_disc_output_linear, fake_disc_output_sigmoid)\n",
        "\n",
        "      generator_loss = generator_loss_fake + 1.0 * generator_loss_class_fake\n",
        "\n",
        "    #Calculate gradients\n",
        "    gen_gradients = g_tape.gradient(generator_loss, self.generator.trainable_variables)\n",
        "    dis1_gradients = d1_tape.gradient(discriminator_loss, self.d1.trainable_variables)\n",
        "    dis2_gradients = d2_tape.gradient(discriminator_loss_class_real, self.d2.trainable_variables)\n",
        "    \n",
        "    # Update weights \n",
        "    self.generator_optimiser.apply_gradients(zip(gen_gradients, self.generator.trainable_variables))\n",
        "    self.d1_optimiser.apply_gradients(zip(dis1_gradients, self.d1.trainable_variables))\n",
        "    self.d2_optimiser.apply_gradients(zip(dis2_gradients, self.d2.trainable_variables))\n",
        "\n",
        "    print(generator_loss)\n",
        "    print(discriminator_loss)\n",
        "    print(discriminator_loss_class_real)\n",
        "\n",
        "    return generator_loss, discriminator_loss\n",
        "\n",
        "  def train(self, training_dataset, training_labels, epochs, save_img_checkpoint, save_model_checkpoint):\n",
        "    fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, SEED_SIZE))\n",
        "    start = time.time()\n",
        "    save_count = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      #Initalise timing and loss lists\n",
        "      epoch_time = time.time()\n",
        "      g_loss_list = []\n",
        "      d_loss_list = []\n",
        "\n",
        "      #Run the step training\n",
        "      for real_images, real_image_labels in zip(training_dataset, training_labels):\n",
        "        t = self.step(real_images, real_image_labels)\n",
        "        g_loss_list.append(t[0])\n",
        "        d_loss_list.append(t[1])\n",
        "      \n",
        "      \n",
        "      #Average losses for entire image batch\n",
        "      average_g_loss = sum(g_loss_list) / len(g_loss_list)\n",
        "      average_d_loss = sum(d_loss_list) / len(d_loss_list)\n",
        "\n",
        "      #Calculate epoch time\n",
        "      epoch_finished = time.time() - epoch_time\n",
        "      print (f'Epoch {epoch + 1}, gen loss={average_g_loss}, disc loss={average_d_loss}, epoch time={hms_string(epoch_finished)}')\n",
        "      \n",
        "      if save_count == 10:\n",
        "        self.save_images(epoch, fixed_seed)\n",
        "        save_count = 0\n",
        "\n",
        "      save_count += 1\n",
        "\n",
        "    final_time = time.time()-start\n",
        "    print (f'Training time: {hms_string(final_time)}')\n",
        "\n",
        "  def save_models(self):\n",
        "    output_model_path = os.path.join(OUTPUT_IMAGE_PATH, self.data_name + \"_Models\")\n",
        "    if not os.path.exists(output_model_path):\n",
        "      os.makedirs(output_model_path)\n",
        "\n",
        "    self.generator.save(os.path.join(output_model_path, f'generator_model_{GENERATE_SQUARE}_res_{GENERATE_RES}_seed_{SEED_SIZE}_epochs_{EPOCHS}_batchSize_{BATCH_SIZE}_bufferSize_{BUFFER_SIZE}.npy'))\n",
        "    self.discriminator.save(os.path.join(output_model_path, f'discriminator_model_{GENERATE_SQUARE}_res_{GENERATE_RES}_seed_{SEED_SIZE}_epochs_{EPOCHS}_batchSize_{BATCH_SIZE}_bufferSize_{BUFFER_SIZE}.npy'))\n",
        "\n",
        "  def load_models(self):\n",
        "    output_model_path = os.path.join(OUTPUT_IMAGE_PATH, self.data_name + \"_Models\")\n",
        "    self.generator = load_model(os.path.join(output_model_path, f'generator_model_{GENERATE_SQUARE}_res_{GENERATE_RES}_seed_{SEED_SIZE}_epochs_{EPOCHS}_batchSize_{BATCH_SIZE}_bufferSize_{BUFFER_SIZE}.npy'))\n",
        "    self.discriminator = load_model(os.path.join(output_model_path, f'discriminator_model_{GENERATE_SQUARE}_res_{GENERATE_RES}_seed_{SEED_SIZE}_epochs_{EPOCHS}_batchSize_{BATCH_SIZE}_bufferSize_{BUFFER_SIZE}.npy'))\n",
        "\n",
        "  def save_images(self, count, noise):\n",
        "    image_array = np.full(( \n",
        "        PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)), \n",
        "        PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), 3), \n",
        "        255, dtype=np.uint8)\n",
        "    \n",
        "    print(image_array.shape)\n",
        "    \n",
        "    generated_images = self.generator.predict(noise)\n",
        "\n",
        "    generated_images = 0.5 * generated_images + 0.5\n",
        "\n",
        "    image_count = 0\n",
        "    for row in range(PREVIEW_ROWS):\n",
        "        for col in range(PREVIEW_COLS):\n",
        "          \n",
        "          r = row * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
        "          c = col * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
        "\n",
        "          # print(\"Rows \", r+GENERATE_SQUARE)\n",
        "          # print(\"Cols \", c + GENERATE_SQUARE)\n",
        "          image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE] = generated_images[image_count] * 255\n",
        "          image_count += 1\n",
        "\n",
        "            \n",
        "    output_path = os.path.join(DATA_PATH,'output')\n",
        "    if not os.path.exists(output_path):\n",
        "      os.makedirs(output_path)\n",
        "    \n",
        "    filename = os.path.join(output_path,f\"train-{count}.png\")\n",
        "    im = Image.fromarray(image_array)\n",
        "    im.save(filename)\n",
        "  \n",
        "  def run(self, new_model, save_img_checkpoint, save_model_checkpoint):\n",
        "    if new_model:\n",
        "      #Build generator and discriminator \n",
        "      self.generator = self.build_generator()\n",
        "      # self.discriminator = self.build_discriminator()\n",
        "      self.d1 = self.build_d1()\n",
        "      self.d2 = self.build_d2()\n",
        "    else:\n",
        "      #Load previous model\n",
        "      self.load_models()\n",
        "\n",
        "    #Compiling G and D\n",
        "    self.compile_models()\n",
        "\n",
        "    # print('Starting training...')\n",
        "    self.train(self.training_dataset, self.training_labels, EPOCHS, save_img_checkpoint, save_model_checkpoint)\n",
        "\n",
        "    # print('Saving generator model...')\n",
        "    # self.save_models()\n",
        "\n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81kOvi7se_gC"
      },
      "source": [
        "#### Running the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7pBBlQQfHqD",
        "outputId": "8590adb7-1c39-44ce-a2dd-06317d04a013"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  can = CAN()\n",
        "  can.run(new_model = True, save_img_checkpoint = 100, save_model_checkpoint = 500)\n",
        "  # can.generator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [01:19<00:00, 19.77s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "8n7BgV6nnQmy",
        "outputId": "d460826d-e34f-4a60-f8a6-4b309eae59c5"
      },
      "source": [
        "# #Create Generator Model\n",
        "# generator = can.generator\n",
        "\n",
        "# #Create Random Noise\n",
        "noise = tf.random.normal([1, SEED_SIZE])\n",
        "\n",
        "# #Image created by the generator with random noise array without any training\n",
        "example_image = can.generator(noise, training = False)\n",
        "# plt.imshow(example_image[0, :, :, 0])\n",
        "print(example_image.shape)\n",
        "\n",
        "print(can.d1.predict(example_image))\n",
        "print(can.d2.predict(example_image))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d59509024f45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# #Create Random Noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEED_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# #Image created by the generator with random noise array without any training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    }
  ]
}