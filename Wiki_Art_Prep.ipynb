{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wiki_Art_Prep.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUuh4kJiUJ1cdmWqeenIOp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meabhl85/Canvas-System/blob/main/Wiki_Art_Prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Eyzb-5k2Rtp"
      },
      "source": [
        "#### Imports and Google Drive Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWVlY3Rn0Dxm",
        "outputId": "620461f5-32fc-46f5-c72c-20d9c2679840"
      },
      "source": [
        "import os \n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "#Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "  h = int(sec_elapsed / (60 * 60))\n",
        "  m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "  s = sec_elapsed % 60\n",
        "  return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sEERa1u2T9_"
      },
      "source": [
        "#### Image Qualities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pAcVcIv0jje"
      },
      "source": [
        "DATA_PATH = 'C:/Users/Meabh/Documents/Uni Work/Honours Project/CAN_System/Wikiart Dataset/wikiart'\n",
        "OUTPUT_PATH = 'C:/Users/Meabh/Documents/Uni Work/Honours Project/CAN_System/Wikiart Dataset/npyFiles'\n",
        "class_count = 0\n",
        "class_names = []\n",
        "\n",
        "#Image Sizes\n",
        "GENERATE_RES = 5 # Generation resolution factor \n",
        "GENERATE_SQUARE = 32 * GENERATE_RES # rows/cols (should be square)\n",
        "IMAGE_CHANNELS = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLr_jKKQ0pGK"
      },
      "source": [
        "def image_prep(npy_file, class_name):\n",
        "  #Looking for npy image file\n",
        "  data_path =  os.path.join(DATA_PATH, class_name)\n",
        "  print(f\"Looking for file: {npy_file}\")\n",
        "\n",
        "  start = time.time()\n",
        "  print(\"Loading training images...\")\n",
        "\n",
        "  training_data = []\n",
        "  \n",
        "  count = 0\n",
        "  for filename in tqdm(os.listdir(data_path)):\n",
        "      count += 1\n",
        "      path = os.path.join(data_path, filename)\n",
        "      \n",
        "      #Open, resize and save image to array\n",
        "      image = Image.open(path).resize((GENERATE_SQUARE, GENERATE_SQUARE), Image.ANTIALIAS)\n",
        "      training_data.append(np.asarray(image))\n",
        "      \n",
        "  \n",
        "  #Reshape array\n",
        "  training_data = np.reshape(training_data,(-1, GENERATE_SQUARE, GENERATE_SQUARE, IMAGE_CHANNELS))\n",
        "  training_data = training_data.astype(np.float32)\n",
        "  ##Normalise images to [-1, 1]\n",
        "  training_data = training_data / 127.5 - 1.\n",
        "\n",
        "  print(\"Saving training image binary...\")\n",
        "  np.save(npy_file, training_data)\n",
        "  elapsed = time.time() - start\n",
        "  print (f'Image preprocess time: {hms_string(elapsed)}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZBpMeRd0tjF"
      },
      "source": [
        "filename = 'Realism'\n",
        "npy_file = os.path.join(OUTPUT_PATH, f'{filename}_training_data_{GENERATE_SQUARE}_{GENERATE_SQUARE}.npy')\n",
        "image_prep(npy_file, filename)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}