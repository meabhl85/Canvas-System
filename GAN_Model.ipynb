{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN-Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meabhl85/Canvas-System/blob/main/GAN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL07H-75ZJLG"
      },
      "source": [
        "#### Imports and Google Drive Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvUCPScifmpH",
        "outputId": "714a94ab-30bd-4814-a4d4-395e2b4e2ff9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense \n",
        "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.constraints import Constraint\n",
        "from tensorflow.keras import backend\n",
        "import numpy as np\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from numpy import ones\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os \n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "#Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "  h = int(sec_elapsed / (60 * 60))\n",
        "  m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "  s = sec_elapsed % 60\n",
        "  return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n06LAznnZQA3"
      },
      "source": [
        "#### Model Hyperparamters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWpEG9l4fpRJ"
      },
      "source": [
        "#Image Sizes\n",
        "GENERATE_RES = 5 # Generation resolution factor \n",
        "GENERATE_SQUARE = 32 * GENERATE_RES # rows/cols (should be square)\n",
        "IMAGE_CHANNELS = 3\n",
        "\n",
        "#Input and Output Paths\n",
        "NPY_FILES_PATH = '/content/drive/MyDrive/Colab Notebooks/honours_project/Npy_Files/'\n",
        "OUTPUT_IMAGE_PATH = '/content/drive/MyDrive/Colab Notebooks/honours_project/GAN_Images/'\n",
        "\n",
        "# Preview image \n",
        "PREVIEW_ROWS = 2\n",
        "PREVIEW_COLS = 3\n",
        "PREVIEW_MARGIN = 16\n",
        "\n",
        "# Size vector to generate images from\n",
        "SEED_SIZE = 800\n",
        "EPOCHS = 1000\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 60000\n",
        "\n",
        "GENERATOR_OPT = tf.keras.optimizers.Adam(1.2e-4, 0.4)\n",
        "DISCRIMINATOR_OPT = tf.keras.optimizers.Adam(1.2e-4, 0.4)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gLHKywwZWoL"
      },
      "source": [
        "#### Model Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUKuQ0Pbf0up"
      },
      "source": [
        "class GAN:\n",
        "  def __init__(self, input_data_name):\n",
        "    self.data_name = input_data_name\n",
        "    self.image_shape = (GENERATE_SQUARE, GENERATE_SQUARE, IMAGE_CHANNELS)\n",
        "    self.training_binary_path = os.path.join(NPY_FILES_PATH, self.data_name + f'_training_data_{GENERATE_SQUARE}_{GENERATE_SQUARE}.npy')\n",
        "    self.loss_function = tf.keras.losses.BinaryCrossentropy()\n",
        "    self.output_image_paths = self.data_name\n",
        "\n",
        "    self.output_image_path = os.path.join(OUTPUT_IMAGE_PATH, os.path.join(self.data_name, f'images_square_{GENERATE_SQUARE}_res_{GENERATE_RES}_seed_{SEED_SIZE}_epochs_{EPOCHS}_batchSize_{BATCH_SIZE}_bufferSize_{BUFFER_SIZE}.npy'))\n",
        "    if not os.path.exists(self.output_image_path):\n",
        "      os.makedirs(self.output_image_path)\n",
        "\n",
        "    print(f\"Looking for file: {self.training_binary_path}\")\n",
        "    if not os.path.isfile(self.training_binary_path):\n",
        "      print('Failed loading NPY file...')\n",
        "    else:\n",
        "      print(\"Loading previous training pickle...\")\n",
        "      training_data = np.load(self.training_binary_path)\n",
        "      \n",
        "      #Batch and Shuffle the Data\n",
        "      self.training_dataset = tf.data.Dataset.from_tensor_slices(training_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)  \n",
        "    \n",
        "  \n",
        "  def build_generator(self):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(4*4*256, activation = \"relu\", input_dim = SEED_SIZE))\n",
        "    model.add(Reshape((4, 4, 256)))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(256, kernel_size = 3, padding = \"same\"))\n",
        "    model.add(BatchNormalization(momentum = 0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(256, kernel_size = 3, padding = \"same\"))\n",
        "    model.add(BatchNormalization(momentum = 0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "   \n",
        "    # Output resolution, additional upsampling\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, kernel_size = 3, padding = \"same\"))\n",
        "    model.add(BatchNormalization(momentum = 0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    if GENERATE_RES > 1:\n",
        "      model.add(UpSampling2D(size = (GENERATE_RES, GENERATE_RES)))\n",
        "      model.add(Conv2D(128,kernel_size=3, padding=\"same\"))\n",
        "      model.add(BatchNormalization(momentum = 0.8))\n",
        "      model.add(Activation(\"relu\"))\n",
        "\n",
        "    # Final CNN layer\n",
        "    model.add(Conv2D(IMAGE_CHANNELS, kernel_size=3, padding=\"same\"))\n",
        "    model.add(Activation(\"tanh\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "  def build_discriminator(self):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size = 3, strides = 2, input_shape = self.image_shape, padding = \"same\"))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(64, kernel_size = 3, strides = 2, padding = \"same\"))\n",
        "    model.add(ZeroPadding2D(padding = ((0, 1), (0, 1))))\n",
        "    model.add(BatchNormalization(momentum = 0.8))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(128, kernel_size = 3, strides = 2, padding = \"same\"))\n",
        "    model.add(BatchNormalization(momentum = 0.8))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(256, kernel_size = 3, strides = 1, padding = \"same\"))\n",
        "    model.add(BatchNormalization(momentum = 0.8))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(512, kernel_size = 3, strides = 1, padding = \"same\"))\n",
        "    model.add(BatchNormalization(momentum = 0.8))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "  def generator_loss(self, fake_pred):\n",
        "    #As G wants to create real images the loss is cross entropy of 1's and the generated output\n",
        "    return self.loss_function(tf.ones_like(fake_pred), fake_pred)\n",
        "\n",
        "  def discriminator_loss(self, real_pred, fake_pred):\n",
        "    #D should compare the real predictions to 1 and fake to 0 (as they are the real values)\n",
        "    real_image_loss = self.loss_function(tf.ones_like(real_pred), real_pred)\n",
        "    fake_image_loss = self.loss_function(tf.zeros_like(fake_pred), fake_pred)\n",
        "\n",
        "    #Discriminator uses the complete loss\n",
        "    final_loss = real_image_loss + fake_image_loss\n",
        "    return final_loss\n",
        "\n",
        "  def compile_models(self):\n",
        "    self.generator_optimiser = GENERATOR_OPT\n",
        "    self.discriminator_optimiser = DISCRIMINATOR_OPT\n",
        "\n",
        "  @tf.function\n",
        "  def step(self, real_images):\n",
        "    seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
        "\n",
        "    #Performs automatic differentiation used for backpropagation \n",
        "    with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
        "      #Gnerate images with noise vector\n",
        "      generated_images = self.generator(seed, training = True)\n",
        "\n",
        "      #Put resulting image into the D and return prediction\n",
        "      real_pred = self.discriminator(real_images, training = True)\n",
        "      fake_pred = self.discriminator(generated_images, training = True)\n",
        "\n",
        "      #Calculate loss for both D and G\n",
        "      g_loss = self.generator_loss(fake_pred)\n",
        "      d_loss = self.discriminator_loss(real_pred, fake_pred)\n",
        "\n",
        "    #Calculate gradients\n",
        "    gen_gradients = g_tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "    dis_gradients = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
        "\n",
        "    #Update weights \n",
        "    self.generator_optimiser.apply_gradients(zip(gen_gradients, self.generator.trainable_variables))\n",
        "    self.discriminator_optimiser.apply_gradients(zip(dis_gradients, self.discriminator.trainable_variables))\n",
        "\n",
        "    return g_loss, d_loss\n",
        "\n",
        "  def train(self, data, epochs, save_epoch, save_checkpoint):\n",
        "    fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, SEED_SIZE))\n",
        "    start = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      #Initalise timing and loss lists\n",
        "      epoch_time = time.time()\n",
        "      g_loss_list = []\n",
        "      d_loss_list = []\n",
        "\n",
        "      #Run the step training\n",
        "      for image_batch in data:\n",
        "        losses = self.step(image_batch)\n",
        "\n",
        "        #Record losses\n",
        "        g_loss_list.append(losses[0])\n",
        "        d_loss_list.append(losses[1])\n",
        "      \n",
        "      #Average losses for entire image batch\n",
        "      average_g_loss = sum(g_loss_list) / len(g_loss_list)\n",
        "      average_d_loss = sum(d_loss_list) / len(d_loss_list)\n",
        "\n",
        "      #Calculate epoch time\n",
        "      epoch_finished = time.time() - epoch_time\n",
        "      print (f'Epoch {epoch + 1}, gen loss={average_g_loss}, disc loss={average_d_loss}, epoch time={hms_string(epoch_finished)}')\n",
        "      \n",
        "      #Check for saving\n",
        "      if epoch % save_epoch:\n",
        "        print(\"Saving example image...\")\n",
        "        self.save_images(epoch, fixed_seed)\n",
        "      if epoch % save_checkpoint == 0:\n",
        "        print(\"Saving models...\")\n",
        "        self.save_models()\n",
        "\n",
        "    #End of epoch processing time\n",
        "    final_time = time.time()-start\n",
        "    print (f'Training time: {hms_string(final_time)}')\n",
        "\n",
        "  def save_models(self):\n",
        "    output_model_path = os.path.join(OUTPUT_IMAGE_PATH, self.data_name + \"_Models\")\n",
        "    if not os.path.exists(output_model_path):\n",
        "      os.makedirs(output_model_path)\n",
        "\n",
        "    self.generator.save(os.path.join(output_model_path, f'generator_model_{GENERATE_SQUARE}_res_{GENERATE_RES}_seed_{SEED_SIZE}_epochs_{EPOCHS}_batchSize_{BATCH_SIZE}_bufferSize_{BUFFER_SIZE}.npy'))\n",
        "    self.discriminator.save(os.path.join(output_model_path, f'discriminator_model_{GENERATE_SQUARE}_res_{GENERATE_RES}_seed_{SEED_SIZE}_epochs_{EPOCHS}_batchSize_{BATCH_SIZE}_bufferSize_{BUFFER_SIZE}.npy'))\n",
        "\n",
        "  def load_models(self):\n",
        "    output_model_path = os.path.join(OUTPUT_IMAGE_PATH, self.data_name + \"_Models\")\n",
        "    self.generator = load_model(os.path.join(output_model_path, f'generator_model_{GENERATE_SQUARE}_res_{GENERATE_RES}_seed_{SEED_SIZE}_epochs_{EPOCHS}_batchSize_{BATCH_SIZE}_bufferSize_{BUFFER_SIZE}.npy'))\n",
        "    self.discriminator = load_model(os.path.join(output_model_path, f'discriminator_model_{GENERATE_SQUARE}_res_{GENERATE_RES}_seed_{SEED_SIZE}_epochs_{EPOCHS}_batchSize_{BATCH_SIZE}_bufferSize_{BUFFER_SIZE}.npy'))\n",
        "\n",
        "  #Saves images in cols and rows specified\n",
        "  def save_images(self, count, noise):\n",
        "    image_array = np.full(( \n",
        "        PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)), \n",
        "        PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), 3), \n",
        "        255, dtype=np.uint8)\n",
        "    \n",
        "    #Generate fake images from input noise\n",
        "    generated_images = self.generator.predict(noise)\n",
        "\n",
        "    generated_images = 0.5 * generated_images + 0.5\n",
        "\n",
        "    image_count = 0\n",
        "    for row in range(PREVIEW_ROWS):\n",
        "        for col in range(PREVIEW_COLS):\n",
        "          r = row * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
        "          c = col * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
        "          image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE] \\\n",
        "              = generated_images[image_count] * 255\n",
        "          image_count += 1\n",
        "\n",
        "    filename = os.path.join(self.output_image_path, f\"train-{count}.png\")\n",
        "    im = Image.fromarray(image_array)\n",
        "    im.save(filename)\n",
        "\n",
        "  def show_image(self, data):\n",
        "    plt.figure()\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(data[0])\n",
        "    plt.show()\n",
        "\n",
        "  def run(self, new_model, save_img_checkpoint, save_model_checkpoint):\n",
        "    \n",
        "    if new_model:\n",
        "      #Build generator and discriminator \n",
        "      self.generator = self.build_generator()\n",
        "      self.discriminator = self.build_discriminator()\n",
        "    else:\n",
        "      #Load previous model\n",
        "      self.load_models()\n",
        "\n",
        "    #Compiling G and D\n",
        "    self.compile_models()\n",
        "\n",
        "    print('Starting training...')\n",
        "    self.train(self.training_dataset, EPOCHS, save_img_checkpoint, save_model_checkpoint)\n",
        "\n",
        "    print('Saving generator model...')\n",
        "    self.save_models()\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8KlXGI9aZ0W"
      },
      "source": [
        "#### Running the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "3yayU6luoVFr",
        "outputId": "20b8d1e6-e37f-4768-b5fb-ea64feb09200"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  #Initialise gan class with art style\n",
        "  gan = GAN('Early_Renaissance')\n",
        "\n",
        "  #Run model\n",
        "  gan.run(new_model = True, save_img_checkpoint = 100, save_model_checkpoint = 500)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking for file: /content/drive/MyDrive/Colab Notebooks/honours_project/Npy_Files/Early_Renaissance_training_data_160_160.npy\n",
            "Loading previous training pickle...\n",
            "Starting training...\n",
            "Epoch 1, gen loss=1.7659804821014404, disc loss=1.8178436756134033, epoch time=0:01:00.76\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/honours_project/GAN_Images/Early_Renaissance_Models/generator_model_160_res_5_seed_800_epochs_1000_batchSize_32_bufferSize_60000.npy/assets\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/honours_project/GAN_Images/Early_Renaissance_Models/discriminator_model_160_res_5_seed_800_epochs_1000_batchSize_32_bufferSize_60000.npy/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-483d47827f92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#Run model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_img_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-b8584eb62ebb>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, new_model, save_img_checkpoint, save_model_checkpoint)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting training...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_img_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving generator model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-b8584eb62ebb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, epochs, save_epoch, save_checkpoint)\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m# show_image(image_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mg_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0md_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}